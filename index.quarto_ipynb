{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"ML_derivatives\"\n",
        "subtitle: \"A module to compute high derivatices of noisy time-series.\"\n",
        "author: \n",
        "    - name: \"Mazen Alamir\"\n",
        "      affiliation:  \"CNRS, University of Grenoble Alpes\"\n",
        "      homepage: \"https://www.mazenalamir.fr\"\n",
        "date: April 25, 2025\n",
        "keywords: [\"Signal preocessing\", \"derivatives estimation\", \"denoising\", \"Machine Learning\", \"Python\"]\n",
        "---\n",
        "\n",
        "---"
      ],
      "id": "a24fcccc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`ml_derivatives` is a python module for the computation of high order derivatives (up to order 4 in the current implementation). Two appealing features of the modules are: \n",
        "\n",
        "1. **Automatic tuning**: \n",
        "   \n",
        "    the `ml_derviatives` module enables an automatic tuning of the trade-off involving the bandwidth of the time-series and the level of affecting the measurements. This seems to be absent from the currently available alternatives which always come with tuning parameters that are to be provided by the user. \n",
        "   \n",
        "1. **Confidence interval computation**:  \n",
        "\n",
        "    the `ml_derviatives` module provides (optionally) an estimation of an interval of confidence to which belong the true values of the derivatives with high probabiliy. This might be of great value when the estimated derivatives are extracted to build a model involving the high derivatives. Indeed, regions where the confidence interval is large might be de-selected in order to be excluded from the so-called *training dataset*.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\" title='Tipycal comparison results with available alternatives (unfold to see)'}\n",
        "\n",
        "![Typical comparison results with available alternatives](images/comparison.png){fig-align=\"center\" width=\"80%\"}\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-tip collapse=\"true\" title='Example of derivatives reconstruction with confidence intervals'}\n",
        "\n",
        "::: {.panel-tabset}\n",
        "\n",
        "### Noise 5% / 1.94Hz\n",
        "\n",
        "\n",
        "![Example of derivatives reconstruction with confidence intervals](images/derivatives_reconstruction_1.png){fig-align=\"center\" width=\"80%\"}\n",
        "\n",
        "\n",
        "### Noise 5% / 12.54Hz\n",
        "\n",
        "![Example of derivatives reconstruction with confidence intervals](images/derivatives_reconstruction_2.png){fig-align=\"center\" width=\"80%\"}\n",
        "\n",
        "### Noise 10% / 4.22Hz\n",
        "\n",
        "![Example of derivatives reconstruction with confidence intervals](images/derivatives_reconstruction_3.png){fig-align=\"center\" width=\"80%\"}\n",
        "\n",
        ":::\n",
        "\n",
        ":::\n",
        "\n",
        "For a complete description of the algorithm, see the reference paper [cited below](#citing)\n",
        "\n",
        "Here, Only the main elements are explained briefly for an easy and quick use of the solver. \n",
        "\n",
        "## Installation \n",
        "```default\n",
        "pip install ml_derivatives\n",
        "```\n",
        "\n",
        "## Problem statement {#problem}\n",
        "Given a sequence `yn` of `N` values representing noisy measurements of of a physical signal `y`which is measured using  **fixed acquisition period** `dt` over the time interval $I$. We want to compute an estimation of the `d`-th derivative of the underlying signal over the same time interval leading to the `N` measurement represented in `yn`, namely,  \n",
        "\n",
        "$$\n",
        "\\dfrac{d^d}{dt^d}\\Bigl[y\\Bigr]\\Biggl\\vert_I = \\texttt{estimate\\_derivative(yn, dt, d, ...)}\n",
        "$${#eq-problem}\n",
        "\n",
        "### Limitations {#limitations}\n",
        "\n",
        "::: {.callout-warning title=\"Minimum number of `N`=50 points required.\"} \n",
        "\n",
        "As the derivatives estimator involves an estimation of the bandwidth of the signal and since the precision of this estimation is inversly proportional to the number of points, the current implementation of the module required a minimum number od points `N`=50.\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "::: {.callout-warning title=\"Maximum bandwidth for a given `dt`.\"} \n",
        "\n",
        "Obviously, given the acquisition period `dt`, there is a limitation on the bandwidth of the signal for which derivatives can be computed. For this reason, it is not advisable to attempt estimation beyond the following maximum pulsation: \n",
        "$$\n",
        "\\omega_\\text{max}= \\dfrac{2\\pi}{5\\times \\texttt{dt}}\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.callout-warning title=\"`ml_derivatives` is slower than standard filters although incomparatively more precise\"} \n",
        "\n",
        "It is important to underline that the counterpart of the above nice features is that the processing time is not that of a point-wise filter although computation time remains descently small. See below for more details regarding standard compuation times using the `ml_derivatives` module. \n",
        ":::\n",
        "\n",
        "::: {.callout-warning title='The length of the time-series is limited to 10000'}\n",
        "\n",
        "Since the estimation is based on some stored information, for the sake of memory, the length of the sequence `yn` used as input argument in (@eq-problem) is limited to 10000. If estimation of derivatives for longer sequence is required, please decompose the signal into multiple segments. \n",
        ":::"
      ],
      "id": "75ccd7ff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from ml_derivatives.mld import Derivator\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "nt = 5001\n",
        "omega = 5.0\n",
        "dt = 0.02\n",
        "\n",
        "der = Derivator()\n",
        "t, Y = der.generate_a_time_series(nt, omega, dt)\n",
        "yn = (1+0.05 * np.random.randn(len(Y[0]))) * Y[0]"
      ],
      "id": "b9556744",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::{.embed}\n",
        "<iframe src=\"images/generated_plots.html\" width=\"100%\" height=\"500\"></iframe>\n",
        ":::\n",
        "\n",
        "\n",
        "## The `solve` method {#solve}\n",
        "\n",
        "The solve method is an instance method of the class `Pol`that enables to minimize, maximize or find a root of the polynomial instance calling it. \n",
        "\n",
        "The call for the `solve` method takes the following form:\n",
        "\n",
        "```python\n",
        "\n",
        "solution, cpu = pol.solve(x0,...)   \n",
        "\n",
        "# see the list of arguments below\n",
        "# with their default values if any.\n",
        "```\n",
        "\n",
        "### Input arguments \n",
        "The table below describes the input arguments of the `solve` method.\n",
        "\n",
        ":::{.tbl-caption}\n",
        "#### Input arguments of the `solve` method.\n",
        "| **Parameter**     | **Description**      | **Default**|\n",
        "|---|---------------|----:|\n",
        "| `x0` |  The initial guess for the solver. This is a vector of dimension `nx`. Notice that when several starting points are used (`Ntrials`>1 as explained below), the next initial guesses are randomly sampled in the admissible domain defined by `xmin` and `xmax`. | --|\n",
        "| `xmin`| The vector of lower bounds of the decision variables| -- |\n",
        "| `xmax`| The vector of lower bounds of the decision variables| -- |\n",
        "| `Ntrials`| The number of different starting points used in order to enhance the avoidance of local minima.| 1 |\n",
        "\n",
        "Table: Input arguments for the `solve`method of the class `Pol`.\n",
        ":::\n",
        "\n",
        "### Output arguments \n",
        "\n",
        ":::{.tbl-caption}\n",
        "#### Output arguments of the `solve`method.\n",
        "| **parameters** | **Description** |\n",
        "|---|----------------|\n",
        "| `solution`| A python `namedtuple` object containing the solution provided by the `solve` method. The dictionary show the following fields: <br> <br> - `x`: The best solution found <br> - `f`: the corresponding best value <br> <br> Therfore, the best solution and the best values can be obtained through `solution.x` and `solution.f`.|\n",
        "| `cpu` | The computation time needed to perform the compuations. |\n",
        "\n",
        ":::\n",
        "\n",
        "## Examples of use {#example}\n",
        "\n",
        "The following script gives an example of a call that asks for the maximization of the polynomial defined earlier (see then prints the results so obtained:\n",
        "\n",
        "```python\n",
        "nx = 3\n",
        "x0 = np.zeros(nx)\n",
        "ntrials = 6\n",
        "ngrid = 1000\n",
        "xmin = -1*np.ones(nx)\n",
        "xmax = 2*np.ones(nx)\n",
        "\n",
        "solution, cpu = pol.solve(x0=x0, \n",
        "                          xmin=xmin, \n",
        "                          xmax=xmax, \n",
        "                          ngrid=ngrid, \n",
        "                          Ntrials=ntrials, \n",
        "                          psi=lambda v:-v\n",
        "                          )\n",
        "                          \n",
        "print(f'xopt = {solution.x}')\n",
        "print(f'fopt = {solution.f}')\n",
        "print(f'computation time = {solution.cpu}')\n",
        "\n",
        ">> xopt = [-1.  2.  0.]\n",
        ">> fopt = 16.0\n",
        ">> computation time = 0.0046999454498291016\n",
        "```\n",
        "\n",
        "Changing the argument `psi`to `psi=lambda v:abs(v)` asks the solver to zero the polynomial and hence, leads to the following results:\n",
        "\n",
        "```python\n",
        ">> xopt = [-0.996997    0.58858859  0.63963964]\n",
        ">> fopt = -9.305087356087371e-05\n",
        ">> computation time = 0.003011941909790039\n",
        "```\n",
        "\n",
        "Finally, using the default definition leads to `solve` trying to find a minimum of the polynomial leading to:\n",
        "\n",
        "```python \n",
        ">> xopt = [-1. -1.  2.]\n",
        ">> fopt = -6.0\n",
        ">> computation time = 0.005150318145751953\n",
        "```\n",
        "\n",
        "## Citing ml_derivatives {#citing}\n",
        "\n",
        "\n",
        "```bibtex\n",
        "@misc{alamir2025reconstructinghighderivativesnoisy,\n",
        "      title={On reconstructing high derivatives of noisy time-series with confidence intervals}, \n",
        "      author={Mazen Alamir},\n",
        "      year={2025},\n",
        "      eprint={2503.05222},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={eess.SY},\n",
        "      url={https://arxiv.org/abs/2503.05222}, \n",
        "}\n",
        "```\n",
        "\n",
        "::: {.callout-note}\n",
        "The above reference contains a detailed description of the algorithm together with an extensive comparison with the best available alternatives. It also explain the general targeted scope of the module that mainly focus on extracting high derivatives from noisy time-series in the aim of building learning datasets that contains *virtual sensor*-like columns representing derivatives of different orders of the raw columned coming from the ground measurements. \n",
        ":::"
      ],
      "id": "a090aa98"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/alamirm/Documents/dev-resources/shared_venvs/venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}